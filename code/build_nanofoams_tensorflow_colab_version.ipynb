{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolasvazquez95/nanofoams_utils/blob/main/scripts/build_nanofoams_tensorflow_colab_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6q7lrqS_ozT"
      },
      "source": [
        "# Input files and scripts ðŸ˜€"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXijmuRU_x9N"
      },
      "source": [
        "## Input file "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XysRZZg299m1",
        "outputId": "1deff86c-25ed-4a5d-84cb-e7cd0d7984cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting 150a0_161.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile 150a0_161.txt\n",
        "###############################\n",
        "# Input script nanofoams_input.txt\n",
        "# For using with script build_nanofoams.py (CPU Parallel version) or with the TensorFlow version\n",
        "# Nota: The units of measure can be chosen by user (use always the same units!)\n",
        "###############################\n",
        "\n",
        "# Lattice type (Cubic:0,BCC:1,FCC:2) (if the value is different of 1 or 2, lattice is cubic by default)\n",
        "1\n",
        "\n",
        "# Box size: x_size y_size z_size (Units AA)\n",
        "495.45\n",
        "495.45\n",
        "495.45\n",
        "\n",
        "# Lattice parameter\n",
        "3.303\n",
        "\n",
        "# Solid fraction of foams\n",
        "0.30\n",
        "\n",
        "# F data\n",
        "# Mean size ligament diamenter (this value can be a little different when the foam is generated, the program informs the user of the changes)\n",
        "22.2177\n",
        "# Number of waves\n",
        "15000\n",
        "\n",
        "# a constant \n",
        "495.45\n",
        "\n",
        "# Random seed\n",
        "462022"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCaPn3Rg_TLW"
      },
      "source": [
        "## H_generator.py (generator of directions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tmq6iAi_7TD",
        "outputId": "3b6367df-e16f-4085-e090-d1b81b4ffaae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting H_generator.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile H_generator.py\n",
        "\n",
        "#############################\n",
        "# Directions generator from a given value H\n",
        "### How to use? Type in command line\n",
        "    ## python H_generator.py H2value1 H2value2 ... H2valuen\n",
        "# Se crearÃ¡n entonces archivos para cada valor de H separado, con las direcciones generadas.\n",
        "# For each given value of H, a file will be created, with the directions generated.\n",
        "# Last modification: 18/02/22\n",
        "## We've added a function makeH2database for databases. \n",
        "#   from H_generator import makeH2database\n",
        "#   makeH2database(H2max,threshold,filename) \n",
        "#############################\n",
        "\n",
        "# Modules\n",
        "import sys\n",
        "import numpy as np\n",
        "import itertools\n",
        "import random\n",
        "\n",
        "def H2_shortlist(H2):\n",
        "    '''\n",
        "    It returns a list of Miller indices (h,k,l), which are solutions of the equation\n",
        "    H^2=h^2+k^2+l^2. Also, the values satisfy h>k>l.\n",
        "    Input: H2 (H^2 value)\n",
        "    '''\n",
        "    HKL = []\n",
        "    for h in range(H2):\n",
        "        for k in range(h,int(np.sqrt(H2)+1)):\n",
        "            for l in range(k,int(np.sqrt(H2)+1)):\n",
        "                if (h**2+k**2+l**2==H2):\n",
        "                    hkl = [h,k,l]\n",
        "                    HKL.append(hkl)\n",
        "    return HKL\n",
        "\n",
        "def HKL_sign(hkl):\n",
        "    '''\n",
        "    It returns all possible permutations of (h,k,l) changing signs (+-)\n",
        "    Input: shortlist [h,k,l]\n",
        "    '''\n",
        "    combinations = []\n",
        "    if hkl.count(0)== 0: # Caso sin ceros\n",
        "    # Pick up two random elements\n",
        "        options = [(0,1),(0,2),(1,2)]\n",
        "        choice = random.choice(options)\n",
        "        for sign_1 in (1,-1):\n",
        "            my_hkl = list(hkl)\n",
        "            my_hkl[choice[0]] = sign_1*my_hkl[choice[0]]\n",
        "            for sign_2 in (1,-1):\n",
        "                my_hkl[choice[1]] = sign_2*my_hkl[choice[1]]\n",
        "                combinations.append(np.array(my_hkl))\n",
        "        return combinations\n",
        "    elif hkl.count(0)==1: # 1 zero case\n",
        "        index_0 = hkl.index(0)\n",
        "        my_hkl = list(hkl)\n",
        "        options = [0,1,2]\n",
        "        del options[index_0]\n",
        "        choice = random.choice(options)\n",
        "        for sign in (1,-1):\n",
        "            my_hkl[choice] = sign*my_hkl[choice]\n",
        "            combinations.append(np.array(my_hkl))\n",
        "        return np.array(combinations)\n",
        "    else: # 2 zeros\n",
        "        return [np.array(hkl)]\n",
        "\n",
        "def total_directions(H2,unpack=False):\n",
        "    '''\n",
        "    Ir returns a list of lists, with every possible combination of vectors, all of them build from a given H^2 value.\n",
        "    Input: H2 (valor de H^2).If unpack=True, it returns a single list with all directions.\n",
        "    '''\n",
        "    directions = []\n",
        "    shortlists = H2_shortlist(H2)\n",
        "    \n",
        "    for shortlist in shortlists:\n",
        "        if shortlist.count(0)<2:\n",
        "            permutations = list(itertools.permutations(shortlist))\n",
        "            # Delete equivalent elements\n",
        "            permutations = list(dict.fromkeys(permutations))\n",
        "        else:\n",
        "            permutations = []\n",
        "            h,k,l = shortlist\n",
        "            permutations.append([h,k,l]);permutations.append([l,h,k]);permutations.append([k,l,h])\n",
        "            \n",
        "        for permutation in permutations:\n",
        "            if unpack==False:\n",
        "                directions.append(HKL_sign(permutation))\n",
        "            else:\n",
        "                vectors = HKL_sign(permutation)\n",
        "                for vector in vectors:\n",
        "                    directions.append(vector)\n",
        "    return directions\n",
        "\n",
        "def writeH2_file(H2,filename):\n",
        "    \"\"\"\n",
        "    It saves a txt file with the directions generated.\n",
        "    Input: H2,filename\n",
        "    \"\"\"\n",
        "    directions = total_directions(H2,unpack=True)\n",
        "    header = 'H2 value: '+str(H2)+'\\n'\n",
        "    header2 = 'Number of directions: '+ str(len(directions))\n",
        "    np.savetxt(filename,directions,fmt=\"%d\",header=header+header2)\n",
        "\n",
        "def makeH2database(H2max,threshold,filename='H2_database.txt'):\n",
        "    \"\"\"\n",
        "    It creates a file 'filename.txt' from a H^2 value y and number of possible directions, only if N_Dir>=threshold,\n",
        "    from 0 to H2max.\n",
        "    \"\"\"\n",
        "    Dir = []\n",
        "    N = []\n",
        "    for i in range(H2max):\n",
        "        if total_directions(i)==None:\n",
        "            Dir.append(0)\n",
        "        else:\n",
        "            Dir.append(len(total_directions(i,unpack=True)))\n",
        "        N.append(i)\n",
        "        print('{}/{} completed.'.format(i+1,H2max),end='\\r',flush=True)\n",
        "    Dir = np.array(Dir,dtype=np.int32)\n",
        "    N = np.array(N,dtype=np.int32)\n",
        "    \n",
        "    Dir_N = np.column_stack((N,Dir))\n",
        "    Dir_N_filtrada = Dir_N[Dir_N[:,1]>=threshold]\n",
        "    np.savetxt(filename,Dir_N_filtrada,fmt='%d',header='H2 Database - Max value {}, Min Directions {}'.format(H2max,threshold))\n",
        "# main\n",
        "if __name__ == \"__main__\":\n",
        "    for i in range(1,len(sys.argv)):\n",
        "        H2 = sys.argv[i]\n",
        "        filename = 'H2_'+H2+'.txt'\n",
        "        writeH2_file(int(H2),filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8ENIUy9Den8"
      },
      "source": [
        "# The program"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQoyFZutyRdR"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "sscnWXbRDhan"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "from scipy import special\n",
        "from os.path import exists as file_exists"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8frZO6GDoPI"
      },
      "source": [
        "## Read input script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "KgUCM2x3DLax"
      },
      "outputs": [],
      "source": [
        "input_script = '150a0_161.txt'\n",
        "struct_info = np.loadtxt(input_script,dtype=np.float32)\n",
        "\n",
        "lattice = int(struct_info[0])\n",
        "\n",
        "x_size = struct_info[1]\n",
        "y_size = struct_info[2]\n",
        "z_size = struct_info[3]\n",
        "\n",
        "lattice_parameter = struct_info[4]\n",
        "\n",
        "phi_b = struct_info[5]\n",
        "if not (0<=phi_b<=1):\n",
        "    raise Exception('phi_b must be a number between 0 and 1.')\n",
        "\n",
        "## With phi_b we can calculate xi, as in Soyarslan paper\n",
        "xi = np.sqrt(2)* sp.special.erfinv(2*phi_b-1)\n",
        "\n",
        "# Number of waves\n",
        "N = int(struct_info[7])\n",
        "# a constant\n",
        "a = struct_info[8]\n",
        "\n",
        "# Reduced box sizes\n",
        "x_size_reduced = int(x_size / lattice_parameter)\n",
        "y_size_reduced = int(y_size / lattice_parameter)\n",
        "z_size_reduced = int(z_size / lattice_parameter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiuxLTayDrpB",
        "outputId": "48f8bfbc-3bcb-46d1-f191-3a474427c364"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using existing directions file H2_database.txt\n",
            "H^2 value calculated: 161.00007068500597\n",
            "Nearest value of H^2 in database: 161\n",
            "New L_mean: 22.217704007987045\n",
            "Relative error in mean ligament diameter: 2.231141310593543e-07 \n",
            "\n",
            "Using existing directions file H2_161.txt\n",
            "Loading directions from txt... Ready.\n",
            "\n",
            "Initializing phases and vectors...\n",
            "Phi shape: (96, 156)\n",
            "Number of waves, Number of directions: (14976, 96)\n",
            "Mean phi,Std phi:  (0.020793345, 1.835302)\n",
            "Mean wave direction: [0.02642036 0.02430674 0.03804532] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# H_generator import and run\n",
        "import H_generator\n",
        "\n",
        "if not file_exists('H2_database.txt'):\n",
        "    H_generator.makeH2database(500, 48)\n",
        "    print('Warning: H2_database.txt not found. New database file created instead.')\n",
        "else:\n",
        "    print('Using existing directions file '+'H2_database.txt')\n",
        "\n",
        "H2_database = np.loadtxt('H2_database.txt',dtype=np.int32)\n",
        "L_mean = struct_info[6]\n",
        "a = struct_info[8]\n",
        "H2_real = ((a/L_mean)*(0.53*phi_b+0.41))**2\n",
        "\n",
        "print('H^2 value calculated:',H2_real)\n",
        "    \n",
        "def find_nearest(array, value):\n",
        "    array = np.asarray(array)\n",
        "    idx = (np.abs(array - value)).argmin()\n",
        "    return array[idx]\n",
        "    \n",
        "H2_final = find_nearest(H2_database[:,0],H2_real)\n",
        "    \n",
        "print('Nearest value of H^2 in database:',H2_final)\n",
        "    \n",
        "L_mean_new = (a/np.sqrt(H2_final))*(0.53*phi_b+0.41)\n",
        "print('New L_mean:',L_mean_new)\n",
        "print('Relative error in mean ligament diameter:',np.abs(1-(L_mean/L_mean_new)),'\\n')\n",
        "\n",
        "filename_H2 = 'H2_'+str(H2_final)+'.txt'\n",
        "\n",
        "if not file_exists(filename_H2):\n",
        "    H_generator.writeH2_file(H2_final, filename_H2)\n",
        "    print('Directions file created.\\n')\n",
        "else:\n",
        "    print('Using existing directions file '+filename_H2)\n",
        "\n",
        "# Directions from txt\n",
        "print(\"Loading directions from txt...\",end='',flush=True)\n",
        "directions = tf.constant(np.loadtxt(filename_H2,dtype=np.float32))\n",
        "N_dir = len(directions)\n",
        "\n",
        "pi2a = 2*np.pi/a\n",
        "q0 = pi2a * np.sqrt(H2_final)\n",
        "Qi = pi2a * directions\n",
        "print(\" Ready.\\n\")\n",
        "# Set seed\n",
        "random_gen = tf.random.Generator.from_seed(int(struct_info[9]))\n",
        "tf.random.set_seed(int(struct_info[9]))\n",
        "\n",
        "print(\"Initializing phases and vectors...\")\n",
        "# Inicializamos array de fases\n",
        "Phi = np.pi*(-1 + 2*random_gen.uniform(shape=(N_dir,int(N/N_dir))))\n",
        "print('Phi shape:',Phi.shape)\n",
        "Qi = pi2a * directions\n",
        "print('Number of waves, Number of directions:',(Phi.shape[0]*Phi.shape[1],N_dir))\n",
        "print(\"Mean phi,Std phi: \",(tf.math.reduce_mean(Phi).numpy(),tf.math.reduce_std(Phi).numpy()))\n",
        "print(\"Mean wave direction:\",(1/N_dir)*tf.math.reduce_sum(Qi,axis=0).numpy(),'\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSsBGFwQEUq1"
      },
      "source": [
        "## Meshgrid creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-crAMaayFm1G",
        "outputId": "57a07d5c-d03b-478c-e85e-030d21b47102"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating meshgrid...\n",
            "Lattice type: BCC\n",
            "Ready. Number of atoms: 6750000 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Creating meshgrid...\")\n",
        "x,y,z = tf.meshgrid(range(x_size_reduced),range(y_size_reduced),range(z_size_reduced),indexing='ij')\n",
        "x = lattice_parameter*tf.cast(x,tf.float32)\n",
        "y = lattice_parameter*tf.cast(y,tf.float32)\n",
        "z = lattice_parameter*tf.cast(z,tf.float32)\n",
        "\n",
        "_x = tf.reshape(x, (-1,1))\n",
        "_y = tf.reshape(y, (-1,1))\n",
        "_z = tf.reshape(z, (-1,1))\n",
        "\n",
        "points = tf.squeeze(tf.stack([_x, _y,_z], axis=-1))\n",
        "\n",
        "if lattice == 1: \n",
        "    print('Lattice type: BCC')\n",
        "    x_bcc = x + lattice_parameter/2\n",
        "    y_bcc = y + lattice_parameter/2\n",
        "    z_bcc = z + lattice_parameter/2\n",
        "    \n",
        "    _x_bcc = tf.reshape(x_bcc, (-1,1))\n",
        "    _y_bcc = tf.reshape(y_bcc, (-1,1))\n",
        "    _z_bcc = tf.reshape(z_bcc, (-1,1))\n",
        "    \n",
        "    points_bcc = tf.squeeze(tf.stack([_x_bcc, _y_bcc,_z_bcc], axis=-1))\n",
        "    \n",
        "    points = tf.concat([points,points_bcc],axis=0)\n",
        "\n",
        "    del x_bcc,y_bcc,z_bcc\n",
        "elif lattice==2:\n",
        "    print('Lattice type: FCC')\n",
        "    x_fcc = x + lattice_parameter/2\n",
        "    y_fcc = y + lattice_parameter/2\n",
        "    z_fcc = z + lattice_parameter/2\n",
        "    \n",
        "    _x_fcc = tf.reshape(x_fcc, (-1,1))\n",
        "    _y_fcc = tf.reshape(y_fcc, (-1,1))\n",
        "    _z_fcc = tf.reshape(z_fcc, (-1,1))\n",
        "    \n",
        "    points_fcc_xy = tf.squeeze(tf.stack((_x_fcc, _y_fcc, _z), axis=-1))\n",
        "    points_fcc_xz = tf.squeeze(tf.stack((_x_fcc, _y, _z_fcc), axis=-1))\n",
        "    points_fcc_yz = tf.squeeze(tf.stack((_x, _y_fcc, _z_fcc), axis=-1))\n",
        "    points = tf.concat((points,points_fcc_xy,points_fcc_xz,points_fcc_yz),axis=0)\n",
        "\n",
        "    del x_fcc,y_fcc,z_fcc\n",
        "else:\n",
        "    print('Lattice type: Cubic')\n",
        "    pass\n",
        "\n",
        "# Delete meshgrid \n",
        "del x,y,z \n",
        "\n",
        "NParticles = points.shape[0]\n",
        "print(\"Ready. Number of atoms: \"+str(NParticles),'\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Yw-LaJJxudO"
      },
      "source": [
        "## $f$ evaluation in mesh grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kS6DqDgGF4Q6",
        "outputId": "78458292-5eee-43f3-de3a-39d5726cd761"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating f in lattice...\n",
            "Batch size: 32 \n",
            "Allocating batches...\n",
            "Ready. Number of batches: 210938\n"
          ]
        }
      ],
      "source": [
        "print(\"Evaluating f in lattice...\")\n",
        "sqr2N = np.sqrt(2/N).astype(np.float32)\n",
        "# Batches allocation\n",
        "batch_size=32 # Hyperparameter\n",
        "print(\"Batch size:\",batch_size,'\\nAllocating batches...')\n",
        "# A function for the batches generation\n",
        "def make_batches(NParticles=NParticles,batch_size=batch_size):\n",
        "    if NParticles%batch_size==0:\n",
        "        return int(NParticles/batch_size)\n",
        "    else:\n",
        "        splits = []\n",
        "        _NParticles = NParticles\n",
        "        while _NParticles>batch_size:\n",
        "            splits.append(batch_size)\n",
        "            _NParticles-=batch_size\n",
        "        splits.append(NParticles%batch_size)\n",
        "        return tf.constant(splits)\n",
        "point_batches = tf.split(points,num_or_size_splits=make_batches(),axis=0)\n",
        "print(\"Ready. Number of batches:\",len(point_batches))\n",
        "# Define a function which evaluates f for one batch\n",
        "@tf.function\n",
        "def chunk_f(batch):\n",
        "    grid_dot = tf.tensordot(Qi,tf.transpose(batch),axes=1)\n",
        "    terms = tf.cos(tf.transpose([grid_dot]) + Phi)\n",
        "    return sqr2N*tf.math.reduce_sum(terms,axis=(1,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3dda681-2ad7-4821-9588-581e47531f3a",
        "id": "ifXXYC90wzsB"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 19565/210938 [=>............................] - ETA: 2:19"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function ScopedTFGraph.__del__ at 0x7fb4697f5d40>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/c_api_util.py\", line 53, in __del__\n",
            "    def __del__(self):\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 58751/210938 [=======>......................] - ETA: 1:45"
          ]
        }
      ],
      "source": [
        "# Iterate over the whole set\n",
        "progbar = tf.keras.utils.Progbar(len(point_batches))\n",
        "f = []\n",
        "for n,batch in enumerate(point_batches):\n",
        "  f.append(chunk_f(batch))\n",
        "  progbar.update(n)\n",
        "# Classify particles\n",
        "f = tf.concat(f,axis=0)\n",
        "@tf.function\n",
        "def type_particle(f):\n",
        "    if f>xi or  tf.experimental.numpy.isclose(f,xi):\n",
        "        return 2 # Void\n",
        "    else: return 1 # Solid\n",
        "types = tf.vectorized_map(type_particle,f)\n",
        "print(\"\\nEvaluation completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bF70kAdIY83"
      },
      "source": [
        "## Save data file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqjuJHGqIzIH",
        "outputId": "82aacc27-6a2d-4515-9ad1-b50c6938df8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving data file...\n",
            "Data file saved succesfully.\n",
            "Exiting program...\n"
          ]
        }
      ],
      "source": [
        "print(\"Saving data file...\")\n",
        "# OVITO preamble\n",
        "timestep = \"ITEM: TIMESTEP \\n0\\n\"\n",
        "NAtoms = \"ITEM: NUMBER OF ATOMS \\n\"+str(NParticles)+'\\n'\n",
        "bounds = \"ITEM: BOX BOUNDS pp pp pp \\n\"\n",
        "\n",
        "size_x = '0.0 '+str(x_size)+'\\n'\n",
        "size_y = '0.0 '+str(y_size)+'\\n'\n",
        "size_z = '0.0 '+str(z_size)+'\\n'\n",
        "dimensions = size_x+size_y+size_z\n",
        "properties = \"ITEM: ATOMS id type x y z f\"\n",
        "\n",
        "preamble = timestep+NAtoms+bounds+dimensions+properties\n",
        "# Build a matrix for the whole set of data\n",
        "ID = [i+1 for i in range(NParticles)]\n",
        "data = np.column_stack([ID,types.numpy(),points[:,0].numpy(),points[:,1].numpy(),points[:,2].numpy(),f.numpy()])\n",
        "# Save file\n",
        "np.savetxt('data_'+input_script[:-4]+'.txt',data,fmt='%d %d %f %f %f %f',header=preamble,comments='')\n",
        "print(\"Data file saved succesfully.\\nExiting program...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get dump file"
      ],
      "metadata": {
        "id": "M7MhiuaKi7px"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# It only download in Google Chrome\n",
        "from google.colab import files\n",
        "files.download('data_'+input_script[:-4]+'.txt') \n",
        "\n",
        "# Google Drive connection! It's faster than Colab. Copy files there and download from Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "TY31UI5VWrKL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "aCaPn3Rg_TLW"
      ],
      "name": "build_nanofoams_tensorflow_colab_version.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python (tf2)",
      "language": "python",
      "name": "tf2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}